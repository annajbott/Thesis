\chapter{\label{ch:4-Pipelines}Computational method development}

%\minitoc

\section{Introduction}

\subsection{Reproducible workflows}
In data analysis, particularly in bioinformatics, many users often create simple bash or R scripts to execute the specific task at hand.
However, if this is done frequently, the user will have an accumulation of these single-use scripts, which are often named uninformatively and never used again.
This may mean the user creates numerous scripts which perform the same function.
Another example of a bad practice is using the command line alone to perform tasks.
This means that exactly how the analysis was performed is not recorded and may be lost or difficult to find later.
These are bad practices in terms of efficiency and reproducibility.
It is much better practice to create well-documented, generalised workflows which can then be applied to multiple different experiments.
This enables the user to reuse their code more easily and reproduce results, if need be.
This also allows other researchers to reproduce results or apply the code to their own research.

In addition to creating generalised, reproducible workflows, it can be beneficial to create more extensive computational pipelines for jobs which require multiple tasks or actions to be performed sequentially.

\subsection{Computational pipelines}\label{subsec:computational_pipelines}
A computational pipeline consists of a series of manipulations and transformations, where the output of one element is the input of the next.
Often these elements are executed in parallel.
Pipelining `omics' data-processing means that tasks that are not interdependent can be executed simultaneously.
Additionally, multiple samples can be processed in parallel, thereby reducing run time.
There are many available pipelining frameworks, for example Snakemake\cite{koster2012snakemake}, Luigi and Ruffus\cite{goodstadt2010ruffus}.

For this work, a series of computational pipelines and workflows were generated.
Ruffus and CGAT-core\cite{cribbs2019cgat} were used as the backbone for the pipelines developed.

\section{scRNA-Seq pseudoalignment pipeline}\label{sec:scRNA_pipeline}
Fewer pipelines exist for single-cell RNA-Seq compared to bulk RNA-Seq.
For the Chromium 10X Genomics platform, most of the processing and analysis is automated by Cell Ranger;
however for other technologies, the workflow is not as well defined.
A single-cell analysis pipeline was constructed with the aim to produce an easy-to-use, robust and reproducible workflow that works for Drop-Seq as well as 10X technology, which utilises pseudoalignment rather than traditional mapping methods.

\subsection{Psuedoaligment}
Traditional mapping techniques such as Tophat\cite{trapnell2009tophat} or STAR\cite{dobin2013star}, rely on aligning each read to a reference genome.
This is generally very time consuming and computationally expensive.
Another challenge that arises with traditional mapping is the occurrence of multi-mapping, whereby a read cannot be uniquely aligned as it could map equally well to multiple sites in the genome\cite{mortazavi2008mapping}.
More recently, a series of methods called pseudoaligners have been developed that overcome some of the issues associated with traditional mapping approaches.
Pseudoalignment (sometimes referred to as quasi-mapping) methods provide a lightweight, alignment-free alternative to traditional mapping.
It has been shown that information on where exactly inside transcripts sequencing reads may have originated is not required for accurate quantification of transcript abundances\cite{nicolae2010estimation}.
Rather, only which transcript the read could have originated from is needed and transcript abundances are calculated by computing the compatibility of reads with different transcripts.
This negates the need for alignment to a reference genome, alleviating the issue of multi-mapping and reducing the computational load.
Pseudoaligners have been shown to complete data processing of RNA-seq datasets up to 250-times faster than traditional alignment and quantification approaches\cite{bray2016near}.
Kallisto\cite{bray2016near} and Salmon\cite{patro2017salmon} are tools which implement pseudoalignment.
They have similar speed and accuracy for bulk RNA-seq data\footnote{\url{https://liorpachter.wordpress.com/2017/09/02/a-rebuttal/}}.

\subsubsection{Pseudoalignment of scRNA-seq}
Pseudoalignment tools have recently been developed for droplet-based scRNA-seq analysis (dscRNA-seq).
Additional challenges come with dscRNA-seq data processing, having the extra complication of cellular barcodes (CBs) and unique molecular identifiers (UMIs).
These tools must handle transcript abundance estimation, as with bulk RNA-seq analysis, but also perform CB detection, collapsing of UMIs (arising from PCR duplication of molecules) and barcode error correction.
Kallisto BUS\cite{melsted2018barcode} has been developed as an analysis tool and file format specifically for single-cell analysis, alongside BUStools, for processing of the resultant BUS file\cite{melsted2019modular}.
Salmon Alevin\cite{srivastava2019alevin} has also been developed for single-cell RNA-seq analysis.

\subsubsection{Pipeline outline}
Kallisto BUS or Salmon Alevin performs pseudoalignment and generation of a cell-by-gene expression counts matrix.
Quality control is performed using Scater\cite{mccarthy2017scater} and alevinQC.
Clustering is performed using Seurat3\cite{stuart2019comprehensive} and Monocle\cite{trapnell2014dynamics}.
Clusters are projected onto tSNE and UMAP plots.
Differentially expressed genes are identified by performing non-parametric Wilcoxon tests on $\log_2 TPM$ expression values and Fisher's exact test for comparing expressing cell frequency, these $p$ values combined using Fisher's method.
Multiple comparisons are accounted for by performing the Benjamini-Hochberg correction to adjust the false discovery rate.

%% Flow diagram- pipeline outline
\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/workflow_generation/flowchart_sc.pdf}
\caption[scRNA-Seq pseudoalignment pipeline flowchart]{Flowchart outlining scRNA-Seq pseudoalignment pipeline- PLACEHOLDER- remake figure}
\label{fig:flowchart_scRNA}
\end{figure}
%%

\subsection{Benchmark}\label{subsec:sc_bench}
Benchmarking measures the performance of a method/software relative to other methods available.
Run time and the accuracy of results are often the factors considered in a benchmark.
To be able to calculate the accuracy of results, the `true' results must be known.
This is difficult in scRNA-seq analysis as no gold standard analysis protocol exists.
Instead, methods are compared against simulated results which act as the underlying `ground truth'.

A benchmark was conducted using simulated data, utilising the pseudoalignment pipeline outlined above.
Kallisto BUS/BUStools and Salmon Alevin pseudoalignment methods were both implemented and their performance compared to one another.
Both pseudoalignment tools have previously been compared to traditional mapping tools\cite{melsted2018barcode, srivastava2019alevin} and both showed comparable accuracy levels, therefore this benchmark does not include the performance of traditional mapping methods.

\subsubsection{Simulated data}
Simulated reads with a know ground truth counts matrix were generated as follows:
10X (version 2) fastq files of 4k PBMCs from a healthy human donor were downloaded  \footnote{\url{https://support.10xgenomics.com/single-cell-gene-expression/datasets}}.
These sequencing files were processed using Salmon Alevin.
The resulting Alevin output folder was used as input for Minnow, using Minnow's alevin-mode.
Minnow generates droplet-based scRNA-seq simulated reads, working backwards from a known counts matrix to generating raw sequencing files from which the counts matrix could have originated.
The valid cell barcode list (whitelist) for 10X chemistry was used (\textit{737K-august-2016.txt}\footnote{\url{https://github.com/COMBINE-lab/minnow/blob/master/data/737K-august-2016.txt}}).
Minnow was ran with an error rate of 0.001 and with 12 simulated PCR cycles.
Minnow accounts for core experimental dscRNA-seq characteristics, such as PCR amplification bias, barcode sequencing errors, the presence of doublets and ambiguously mapped reads, to try and emulate a realistic set of sequencing reads consistent with the provided counts matrix.

The ground-truth counts matrix was converted to a Single Cell Experiment object (SCE) and the simulated reads were used as input for the scRNA-Seq pseudoalignment pipeline.
The resulting count matrices outputted by Salmon Alevin and Kallisto BUS were converted into SCEs, subset and reordered so that they all contained the same cells and genes, in the same order.
The Salmon Alevin and Kallisto BUS produced SCEs could then be compared to the ground truth SCE.

%Splatter\cite{zappia2017splatter} was used to simulate single-cell counts matrices, using a real single-cell counts matrix to estimate simulation parameters from.
%The simulated counts matrix was randomly assigned cell barcodes and ensembl gene names for the column and rownames respectively, and then used as input for Minnow\cite{sarkar2019minnow} as `ground-truth' data.
%Minnow generates droplet-based scRNA-seq simulated reads, working backwards from a known counts matrix to generating raw sequencing files from which the counts matrix could have originated.
%Minnow accounts for core experimental dscRNA-seq characteristics, such as PCR amplification bias, barcode sequencing errors, the presence of doublets and ambiguously mapped reads, to try and emulate a realistic set of sequencing reads consistent with the provided counts matrix.
%The simulated reads were used as input for the scRNA-Seq pseudoalignment pipeline and the resulting count matrices outputted by Salmon Alevin and Kallisto BUS were compared to the `ground-truth' data.

\subsubsection{Run time}
The simulated reads consisted of 434 million reads.
Running Salmon Alevin and creating an SCE object took approximately 64 minutes;
running Kallisto BUS, sorting and creating an SCE object took approximately 24 minutes.
Using the bustools `count' command to create a counts matrix may have further reduced run time, however more time would be needed to parse it into R and create an SCE object.

\subsubsection{Cell barcode handling}
The ground-truth data contained 4340 cells.
Alevin determined a threshold for the initial whitelist (a set of CBs that likely represent non-empty droplets) by finding a `knee' in the knee plot shown in Figure \ref{fig:alevin_knee}.
This initial whitelist contained 5261 cell barcodes, each observed at least 191 times.
Following barcode error correction, the final whitelist contained 4340 cells, all of which corresponded to the same CBs as the ground-truth data.

% alevin knee
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/workflow_generation/alevin_knee_plot.png}
    \caption[Benchmark Salmon Alevin Knee Plot]{Alevin knee plot.
    This plot displays the number of times each cell barcode is observed, in decreasing order.
    Finding a `knee' in this plot determines a threshold for the initial whitelist of CBs, which are unlikely to be empty droplets.}
    \label{fig:alevin_knee}
\end{figure}

For Kallisto BUS, valid cell barcodes were determined using either emptyDrops (DropletUtils) or by
using barcodeRanks and calculating the inflection point of a rotated knee plot (where the x- and y- axis are transposed; Figure \ref{fig:bus_knee}).
The inflection point method, gave a whitelist of 4339 cell barcodes (one fewer than the ground truth number), but all 4339 CBs corresponded to ground truth CBs.
emptyDrops gave a total cell number of 12037, only 3746 of which were in the ground truth list of 4340 CBs. This was a large overestimate of number of cells present and the whitelist did not contain all of the valid CBs.
Therefore, using the inflection point of the rotated knee plot was found to be the preferred method of filtering cell barcodes.

% BUS knee
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/workflow_generation/bus_knee_plot.png}
    \caption[Benchmark Kallisto Bus Rotated Knee Plot]{Kallisto BUS rotated knee plot.
    This plot shows the number of distinct UMIs against the rank of the barcode.
    The Pachter lab transpose the x- and y-axis on their knee plot, so that the x-axis displays distinct UMIs and the y-axis displays ranked cell barcodes, according to the number of corresponding UMIs to each CB. This is supposed to be more intuitive, having the number of distinct UMIs as the independent variable rather than cell barcode rank, as number of UMIs determine the cell barcode rank.}
    \label{fig:bus_knee}
\end{figure}

\subsubsection{Gene expression predictive accuracy}
To quantify each tool's accuracy of gene expression, precision, recall and an F1 score were calculated for each gene.
The F1 score is a measure of a test's accuracy, it is the harmonic mean of precision and recall:
% F1 score equation
\begin{equation}
\begin{aligned}
\text{precision} & = \frac{tp}{tp + fp}\\
%
\text{recall} & = \frac{tp}{tp + fn}\\
%
F_{1} & = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{precision + recall}
\end{aligned}
\end{equation}

\textit{Where for each gene: tp = number of true positives, fp = number of false positives, fn = number of false negatives.}
%Carol diagram
\input{text/Chapter_4_Pipelines/carol_fp_tp.tex}

No expression was denoted by 0, and expression by 1.
When recall or precision was undefined, i.e. a gene in Alevin/BUS matrix or the ground-truth matrix was not expressed by any cell, F score was defined as 0.

The mean F1 scores for Alevin and BUS processed data (Figure \ref{fig:precision_recall_f1_bar}) were extremely similar to each other with scores of 0.93 and 0.95, this was due to the large number of F1 scores equal to 1.
Figure \ref{fig:westoby_histogram} shows the distribution of F1 scores more clearly.
Alevin seemed to produce more lower F1 scores than BUS\@.

% Barcharts. Precision recall and F1 score
\begin{figure}[h]
%1
\centering
\begin{subfigure}{0.32\textwidth}
    %\centering
    \includegraphics[width=\textwidth]{figures/workflow_generation/precision_bar.png}
    \caption{Precision}
\end{subfigure}
%2
\begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\textwidth]{figures/workflow_generation/recall_bar.png}
    \caption{Recall}
\end{subfigure}
% 3
\begin{subfigure}{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/workflow_generation/F1_bar.png}
    \caption{F1 Score}
\end{subfigure}
\caption[F1, Precision and Recall Bar Charts]{F1 score.
Two times the product of precision and recall divided by the sum of precision and recall.
Measure of accuracy for the tools ability to predict gene expression.
Expression classified by 0 or 1.
Undefined scores have been removed.
F1 scores were calculated for each gene across each cell.}
\label{fig:precision_recall_f1_bar}
\end{figure}
%
% scatter and histogram
\begin{figure}[h]
%1
\begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\textwidth]{figures/workflow_generation/f1_westoby.png}
    \caption{F1 Score scatter graph}
    \label{fig:f1_westoby}
\end{subfigure}
%2
\begin{subfigure}{0.5\textwidth}
    \includegraphics[width=\textwidth]{figures/workflow_generation/f1_histogram.png}
    \caption{F1 score histogram}
    \label{fig:f1_hist}
\end{subfigure}
\caption[Distribution of F1 scores]{F1 score distributions.
    \ref{fig:f1_westoby} shows the F1 score for each gene expressed across all 4339 cells.
    The black bar denotes the mean F1 score for each cell.
    F1 scores of 0 have been removed.}
\label{fig:westoby_histogram}
\end{figure}

\subsubsection{Clustering}

% clustering
\begin{figure}[ht]
%1
\centering
\begin{subfigure}{0.7\textwidth}
    \includegraphics[width=0.9\textwidth]{figures/workflow_generation/umap.png}
    \caption{UMAP}
    \label{fig:benchmark_UMAP}
\end{subfigure}
\medskip
%2
\begin{subfigure}{0.7\textwidth}
    \includegraphics[width=0.9\textwidth]{figures/workflow_generation/tsne.png}
    \caption{tSNE}
    \label{fig:benchmark_tsne}
\end{subfigure}
\caption[Benchmark Clustering Analysis]{Clustering analysis of the simulated data.
18 clusters are present in the ground truth data and Alevin and BUS processed data.
Integrated clustering was performed using Seruat3\cite{stuart2019comprehensive}, using both Uniform Manifold Approximation and Projection (UMAP) and  t-distributed Stochastic Neighbor Embedding (tSNE) dimension reduction techniques.}
\label{fig:benchmark_clustering}
\end{figure}

Clustering analysis was performed to visualise how well the tools processed the single-cell data and how clusters compared to ground-truth data.
Seurat3 integrative analysis was performed so that the clusters of each sample could be directly compared.
Figure \ref{fig:benchmark_clustering} shows clustering of Alevin, BUS and ground-truth clustered data, using UMAP and tSNE dimension reductions.
18 clusters are present in all three of the data sets.
Visual analysis suggests that the two dscRNA-seq quantification tools compare well to the ground-truth and capture most aspects of the data.
From the benchmark it seems as if both tools are fit for purpose and can accurately quantify gene expression and correctly handle CBs and UMIs.

\afterpage{\clearpage}

%\subsection{Comparison to published data using other methods..}

\subsection{Updated scRNA-seq pipeline}\label{subsec:updated_scrna}
Following the bench-mark it was decided that Kallisto BUS and BUStools would be used to analyse single-cell data.
This was due to its faster run-time and higher F1 scores.
The analysis pipeline has been updated continually throughout the project.
The updated workflow is outlined in Figure \ref{fig:updated_sc_workflow}.
Each major task has been split into separate lightweight pipelines, each containing multiple minor tasks.
The black arrows in Figure \ref{fig:updated_sc_workflow} denote a separate processing pipeline.
This allows the user to analyse the output after each step, and make changes to parameters as they see fit.

Following sequencing, raw FASTQ files are inputted into Kallisto bus.
A bus file is generated along with corresponding information about equivalence classes and transcript names.
Kallisto bustools is used to generate a cell by gene count matrix for each sample.
These matrices are loaded into R and converted to Single cell experiment (SCE) and Seurat objects.
Next, quality control (QC) is performed.
Poor quality cells are removed based on numerous parameters.
Cells with fewer than a set UMI number (the default is 500), cells with a very low or very high gene count (the default minimum and maximum is 300 and 6000, respectively), and cells with mitochondrial content over a certain ratio (the default is 0.1).
This is a user-supervised process, which requires fine-tuning after inspecting graphs and quality metrics.
Parameters can be altered and QC performed again.
Following quality control, each sample is clustered individually by Seurat, then all samples are integrated together, by either Harmony or Seurat's SCTransform functionality.
The integrated dataset is then annotated by cell type by the packages scClassfiy, singleR or clustfyr, in combination with a reference dataset or model.
Often manual annotation by the user (using known biological markers) is required for finer annotation.
The user can then perform further downstream analysis on the annotated integrated dataset, for example differential expression analysis and composition analysis.

% updated scRNA-seq workflow figure
\begin{figure}[p]
\centering
\includegraphics[width=\textwidth]{figures/workflow_generation/sc_workflow.pdf}
\caption[Updated scRNA-seq workflow]{Outline of updated scRNA-seq workflow.
Each black arrow denotes an independent pipeline.
Following sequencing raw FASTQ files are processed by Kallisto bus and bustools and cell x gene count matrices are produced for each sample.
Quality control (QC) is performed, based on a number of parameter thresholds.
QC often requires user supervision to fun-tune the process.
Seurat is then used to perform dimensionality reduction techniques and cluster samples individually.
Harmony and Seurat are implemented to perform sample integration.
The integrated dataset can then be annotated by cell type using packages cClassfiy, singleR or clustfyr, in combination with a reference dataset or model.
The user can then perform further downstream analysis on the dataset, for example differential expression analysis.
}
\label{fig:updated_sc_workflow}
\end{figure}

\afterpage{\clearpage}
\section{scRNA-Seq velocity analysis pipeline}

\subsection{RNA velocity}
scRNA-seq gene expression analyses capture only a static snapshot of the transcriptome in time.
In a seminal paper by La Manno et al. (2018), RNA velocity methods were introduced with the aim of revealing the rate and direction of change of the transcriptome during dynamic processes, such as embryonic development or cellular dynamics following drug treatment\cite{la2018rna}.
In-line with previous observations, the authors found that between 15 and 25\% of scRNA-seq reads contain unspliced intronic sequences.
Using this knowledge, they found that the balance between unspliced and spliced mRNAs can be predictive of cellular state progression, and can be used to directly estimate the time derivative of gene expression on a timescale of hours.
Therefore, using RNA velocity in combination with clustering analysis, the trajectory of a single cell can be tracked.
This paper introduced Velocyto for RNA velocity analysis.
Since its inception in 2018, numerous tools have been developed for RNA velocity analysis\cite{la2018rna, weng2021vetra, bergen2020generalizing, melsted2019modular}.

\subsection{Pipeline outline}
A modular RNA velocity analysis workflow was constructed based around the kallisto BUStools (kb-python wrapper) velocity workflow\cite{melsted2019modular}.
The user requires an Ensembl reference GTF file and DNA fasta file for the species of interest, and their raw fastq read files as input.
Firstly, an RNA velocity index is generated from the GTF and fasta file.
Kb count is then used to generate spliced and unspliced transcript count matrices and a loom file.
The resulting loom files are imported into R, and after some cell barcode manipulation, combined with existing gene-expression-based Seurat objects.
This gives a Seurat object containing gene-expression data, UMAP/tSNE embeddings and spliced/unspliced RNA velocity counts.
If the RNA workflow is combined with an annotated seurat object, the trajectory of individuals cells can then be mapped onto UMAP plots with pre-defined cell-type annotations.
The pipeline is deposited on GitHub and can be found here: \url{https://github.com/annajbott/pipeline_kb_velo}.

% tRNA workflow
\afterpage{\clearpage}
\input{text/Chapter_4_Pipelines/tRNA_methods.tex}

\afterpage{\clearpage}
\input{text/Chapter_4_Pipelines/MM_classifier.tex}

\section{Discussion}

Before the advent of NGS, the bottleneck in omics experiments was the technology available, which severely limited data acquisition.
The duration of time for the completion of sequencing projects was very long (for example the 13 years taken to sequence the human genome).
Since the use of NGS and TGS technologies-- with their higher throughput compared to traditional first-gen techniques-- the bottleneck of omics experiments has shifted to data processing and data discovery.
Over the last two decades, numerous computational methods and tools have been invented to relieve the strain of data processing times.

The ever-increasing volumes of omics-data require data-processing pipelines/workflows that are robust, quick and efficient, whilst possessing the scientific rigour that allows for consistent and fully reproducible analysis of results.
Robust and reproducible genomic workflows allow for confidence in interpreting results in meaningful biological context.

The CGAT framework was used to construct computational pipelines for data processing and extraction of biologically meaningful statistical analyses, summaries and visualisations from input data.
The CGAT-framework was chosen as the base for the computational pipelines in this work because: CGAT-core can handle parallelisation across HPC clusters, it is integrated with the use of Conda environments, it allows for parameterisation of pipelines, it is open-source, and it records detailed logs of progress. Additionally, significant CGAT toolkits are available for specialised bioinformatics tasks.
The large size of omics data means that many computational biologists use HPC clusters to analyse their data, to reduce computing time. Moreover, most cluster users do not have sudo access rights, therefore must use package and virtual environment managers.
Conda integration was an important factor for the pipeline-framework, as other package managers, such as Pip, are mainly for python package installation, whereas Conda is a cross-platform environment manager.
Many bioinformatic tools are written in R and are easily available on the Bioconda channel of Conda.
Logging of pipeline progress allows for easy reproducibility of results.
CGAT pipelines are built on top of Ruffus workflow management.
Compared with other workflow managers, Ruffus has been rated manager with the highest ease of development, such that it requires the least effort to compose new workflows\cite{leipzig2017review}.
This is further adds to its appeal, as it requires less time and effort to create new workflows, but also means that other users should be easily able to debug errors themselves and adapt the workflows as they see fit.

Using the CGAT framework, analysis pipelines were constructed for dscRNA-seq pseudoalignment analysis, scRNA velocity analysis and tRNA-seq analysis.

\subsection{Benchmarks}

Benchmarks were conducted to assess the performance of these pipelines.
A combination of simulated and real data was used to assess performance.
Simulated data allows comparison of the output of a given method to a known `ground-truth'.
This is a key strength of using simulated data as you can directly compare to known scores or values, and quantitatively assess the accuracy of a method.
For transcriptomic data, often the known ground truth data is a counts matrix, either gene x sample for bulk methods or gene x cell for single-cell methods.
Additionally, simulated data can be used as lightweight data for testing, as opposed to using large real-world data. However, using simulated data poses several limitations.
The model under which the simulated data were generated can alter the results of the benchmark and favour certain methods over others.
For example, a benchmark was performed for 12 different scRNA-seq simulation methods, across 35 different datasets\cite{cao2021benchmark}.
The study observed differing results for each method across four evaluative categories (data property estimation, biological signals, scalability and applicability\cite{cao2021benchmark}, indicating that the method of simulating data can affect the performance of a model in a benchmark.
Often authors of a new method or tool perform a benchmark themselves, boasting its superiority over previous methods, without using a systematic assessment procedure (trialling numerous simulated datasets, with varying parameter values), this can lead to biases in their published results-- this is known as the self-assessment trap\cite{mangul2019systematic}.

Secondly, simulated data is unable to capture true experimental variability, and will always be less complex than real-world data\cite{mangul2019systematic}.
It has been shown that various scRNA-seq data simulation methods are unable to reflect the level of heterogeneity seen in a population due to inter-patient variability\cite{cao2021benchmark}.
Considering the pipeline generated in this work will be primarily used to analyse MM data, the benchmark has done little to support that it will be appropriate to infer results from heterogeneous MM patients.

Thirdly, transcriptome simulation methods are unable to simulate reads from intronic and intergenic regions of the genome, or transcripts that are not part of the annotation used to generate the reads.
This complexity is present in experimental datasets.


\subsection{scRNA-seq analysis benchmark}
MM is an extremely heterogeneous disease, with numerous interactions with the surrounding immune microenvironment.
Therefore, to best examine MM and the effects of therapeutics, single-cell techniques are required, including scRNA-seq to study the transcriptome at the single cell level.
To be able to interpret results from scRNA-seq data, a robust and reproducible scRNA-seq analysis pipeline was required.

It has previously been shown using simulated data, that pseudoalignment/ lightweight mapping strategies demonstrate similar accuracy to traditional mapping strategies such as STAR and Bowtie2, yet provide massive improvements in computing time and memory usage.
Therefore, it was decided that only lightweight mapping strategies would be implemented in the scRNA-seq analysis pipeline.
The pipeline was written with the ability for the user too choose either Kallisto BUStools or Salmon Alevin for pseudoalignment.
However, for consistency in the lab's analysis workflow, only one tool would be used for all future scRNA-seq data.
To determine which lightweight mapping method to use, a benchmark was conducted using simulated scRNA seq reads.
From this benchmark Kallisto BUS/BUStools was determined more accurate and faster than Salmon Alevin.
This result has been confirmed by subsequent benchmarks\cite{you2021benchmarking, melsted2019modular, melsted2019barcode}.

More recently, the Patro lab have introduced a reimplementation of Salmon Alevin, called Salmon-Alevin-Fry (SAF)\cite{sarkar2020accurate}.
SAF outputs a file similar to the BUS file, with the aim of quicker compute time and less memory usage.
The Pachter lab (the lab responsible for Kallisto) performed a benchmark of the new SAF framework against Kallisto BUStools\cite{booeshaghi2021benchmarking}.
To avoid the self-assessment trap, both programmes were ran using the developer recommended settings, and compared over many datasets, across a variety of organisms and tissues.
The group used real-world data to compare the methods.
They achieved this by processing the same experimental reads with both SAF and Kallisto BUStools and then combining the SAF processed cells and Kallisto BUStools processed cells together into one dataset.
After dimensionality reduction, the distance between identical cells either processed by SAF or BUS was examined and compared to the next nearest cell.
The group found that gene expression differences between SAF and Kallisto were negligible for clustering analysis and irrelevant for downstream analysis.
They also found that even with the updated SAF framework, Salmon-Alevin-Fry remained significantly slower and required more memory to run than Kallisto BUStools.
This confirms the results of the benchmark conducted in this work and the subsequent decision to use Kallisto BUStools as the lightweight mapper of choice for scRNA-seq analysis.

The benchmark performed in this work used precision, recall and F1 scores to assess accuracy.
These scores use binary classifications, therefore the benchmark only looked at the accuracy of `Expressed' vs `Not expressed' for every gene, across every cell.
This was considered an appropriate measure of accuracy, as the fraction of zeros (cells not expressing a given gene) in a scRNA-seq experiment is extremely high, sometimes exceeding 90\%\cite{linderman2022zero}.
However, the benchmark does not give any information about abundance quantification accuracy.
As such, one of the methods outputting a count value of 1 vs another method outputting a count of 1000 would be considered as the same by the benchmark (i.e. expressed), even though they are clearly very different counts biologically.
Srivastava et al. (2020) investigated the transcript abundance quantification performance of traditional mapping and alignment strategies Bowtie2 and STAR compared to the quasi-mapping (pseudoalignment) method Salmon\cite{srivastava2020alignment}.
The group calculated Spearman correlation of quantification estimates by each alignment method compared to Polyester simulated scRNA-seq ground-truth data.

To demonstrate the application of the pipeline and its effectiveness on MM data, a more comprehensive benchmark could be performed by implementing some of the strategies summarised above.
For simulated data: as well as assessing accuracy of expression vs no expression, gene abundance quantification accuracy should be examined using Spearman correlation statistics.
Real world data should also be included, to assess how methods perform with added experimental complexity and heterogeneity.
Since no ground-truth data is available, it becomes more challenging to analyse accuracy.
The strategy implemented in \cite{booeshaghi2021benchmarking} could be generalised to include all traditional mapping and lightweight mapping technique.
This could be performed by processing a real-world dataset using the numerous mapping/alignment methods, then combining them together into one counts dataset, so that for each biological cell there are numerous `doppelganger' cells each processed by a different method.
Following dimensionality reduction of this matrix, you would expect the `doppelganger' cells originating from the same biological cell to cluster together.
L1 distances from the centroid of these clusters could then be calculated for all of the methods, across every cell in the dataset, to give an overall score for each method and to see how much each method agrees with one another.
This strategy could be implemented for real-world MM data, to ensure the alignment methods chosen are appropriate to analyse MM patient data.

\subsection{MM classifier}
- Aim to classify gene expression profile of MM
- Microarrays

Marker expression and bead enrichment is frequently used in MM research to sort plasma cells prior to sequencing.
During normal B cell development into plasma cells, cells start expressing CD138.
In the bone marrow, CD138 is a specific surface antigen for plasma cells and MM cells\cite{kawano2012multiple}.
The typical approach for isolating plasma cells is to use CD138\textsuperscript{+} magnetic selection;
this can enrich plasma cells around 100 times\cite{bansal2021impact}.
This is useful to offset the high costs of single-cell sequencing, so that a high cell count and read depth can be achieved for MM cells, without sequencing other immune cells, which are often of low importance to researchers.
However, previous studies of MM cell lines and clinical MM samples have shown a small population of MM cells lack CD138 expression\cite{matsui2004characterization}, therefore anti-CD138 antibodies will recognise only a sub-population of MM cells.
CD138 also has a fast turnover on the cell membrane, and is constitutively shed on cultured cells and apoptotic cells\cite{bansal2021impact}.
Passaging in cell culture, sample processing and drug treatment can induce rapid apoptosis in primary myeloma cells, hence leading to CD138 shedding.
Furthermore, CD138\textsuperscript{-} MM cells have been reported to have more proliferative potential than CD138\textsuperscript{+} MM cells and that they play an important role in regulating bone marrow stromal cells\cite{reid2010characterisation, wu2015cd138}.
Matsui et al. (2004) reported the existence of CD138\textsuperscript{-} MM `stem cells', which had greater clonogenic potential than CD138\textsuperscript{+} MM cells and phenotypically resembled postgerminal center B cells\cite{matsui2004characterization}.
A decrease in CD138 expression has also been observed during the course of treatment in some MM patients\cite{kawano2012multiple}.

Therefore, by separating cells based on \textit{CD138} expression, information on a whole subpopulation of MM cells is lost.
Results will be skewed towards CD138\textsuperscript{+} MM cells.
With the large heterogeneity seen in MM and acquired-drug resistance theories regarding MRD and clonal evolution, the entire MM population must be investigated to get an accurate picture of the whole MM landscape.

Bansal et al. (2021) investigated the impact of CD138\textsuperscript{+} magnetic bead-based selection compared to whole bone marrow (WBM) processing on BM plasma cell surface markers\cite{bansal2021impact}.
They found that CD138\textsuperscript{+} selection of PCs appears to change important markers on the PCs, such as substantial loss of expression of D71, CD11b, CD11a, CD69, and CD49e, and also almost a complete loss of CD45\textsuperscript{+} subset of cells in half of cases.
From the study it was not clear if this phenotypic change of PCs was due to antigen loss from the process of selection or if subsets of cells were eliminated/ preferentially selected.
For RNA and DNA-based studies (like scRNA-seq) this would be an issue if a subset of cells were preferentially selected for, as it would further skew results to a smaller subset of total MM cells.

From the above considerations about CD138 expression and selection, together with the established interactions between MM cells and their surrounding immune microenvironment, it seems sequencing the whole bone marrow niche should be the preferred method for MM scRNA-seq studies.
scRNA-seq of the WBM niche is more expensive than isolated PCs (if maintaining a good read depth and high cell count).
It also requires more time, effort and skill to process the data-- for example assigning cell types to clusters.
The MM classifier created in this work aims to address the computational data processing burden of the WBM scRNA-seq method for MM studies.
Hopefully more MM researchers will start adopting the WBM method for scRNA-seq.
As more researchers perform MM WBM scRNA-seq experiments and make the resulting data publically available, MM classifiers can be improved further with more data from heterogeneous patients.



Not many MM scRNA-seq studies investigating whole BM without separating first. Had to find study on pubmed to use as test data
Encourage more researchers to investigate whole niche.
Classifiers to identify risk...
Ground truth, user defined labels.
% Improve more data. More researchers to deposit data sets with whole niche
Recall vs precision
RRMM vs naive





